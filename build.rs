//! Generate the `enum` for supported languages and their identification from a TOML file.
use std::{
    collections::HashMap,
    fs::{self, File},
    io::Write,
    path::Path,
};

use toml::Value;

const LINGUIST_TOML: &str = "linguist.toml";
const OUTPUT_FILE: &str = "src/backend/languages.rs";

const ACCEPTED_SECTIONS: [&str; 4] = ["modelines", "filenames", "shebang", "heuristics"];

fn main() {
    let linguist_contents =
        fs::read_to_string(LINGUIST_TOML).expect("failed to read linguist config file");
    let linguist_toml =
        toml::from_str(&linguist_contents).expect("invalid TOML for linguist config");

    let mut data_sections: HashMap<String, HashMap<String, Vec<String>>> = HashMap::new();

    let mut linguist_code = String::from("//! This file has been auto-generated by 'build.rs'\nuse std::collections::BTreeMap;\nuse glob::Pattern;\n\n#[derive(Debug, Hash, Eq, PartialEq, Copy, Clone, PartialOrd, Ord)]\n#[repr(u8)]");

    if let Value::Table(table) = linguist_toml {
        linguist_code.push_str("pub enum Languages {\n    Binary,\n    PlainText,\n");
        for k in table.keys() {
            if let Value::Table(table) = &table[k] {
                let v = fix_case(k);
                linguist_code.push_str(&format!("    {},\n", v));

                for k1 in table.keys() {
                    if ACCEPTED_SECTIONS.contains(&k1.as_str()) {
                        if let Value::Array(arr) = &table[k1] {
                            let mut vals = Vec::new();
                            for el in arr {
                                if let Value::String(s) = el {
                                    vals.push(s.to_string());
                                } else {
                                    eprintln!("non-string element amongst elements of key '{}' of language '{}'", k1, k);
                                }
                            }

                            if let Some(m) = data_sections.get_mut(k1.as_str()) {
                                m.insert(v.clone(), vals);
                            } else {
                                data_sections.insert(k1.clone(), HashMap::new());
                                let m = data_sections.get_mut(k1.as_str()).unwrap();

                                m.insert(v.clone(), vals);
                            }
                        } else {
                            eprintln!("non-array data for key '{}' of language '{}'", k1, k);
                        }
                    }
                }
            } else {
                eprintln!("no data for language '{}'", k);
            }
        }
        linguist_code.push_str("}\n");
    } else {
        panic!("invalid TOML structure for linguist config");
    }

    for sect in ACCEPTED_SECTIONS {
        let big_sect = sect.to_ascii_uppercase();

        linguist_code.push_str(&format!(
            "\npub static mut {}: BTreeMap<Languages, &[&str]> = BTreeMap::new();\n",
            big_sect
        ));

        if let Some(langs) = data_sections.get(sect) {
            for lang in langs.keys() {
                let vals = &data_sections[sect][lang];

                linguist_code.push_str(&format!(
                    "const {}_{}: [&str; {}] = [",
                    big_sect,
                    lang.to_ascii_uppercase(),
                    vals.len()
                ));

                for val in vals {
                    linguist_code.push_str(&format!("\"{}\", ", val));
                }

                linguist_code.push_str("];\n");
            }
        }
    }

    for sect in ACCEPTED_SECTIONS {
        let big_sect = sect.to_ascii_uppercase();

        linguist_code.push_str(&format!("\nfn init_{}_map() {{\n    unsafe {{\n", sect));

        if let Some(langs) = data_sections.get(sect) {
            for lang in langs.keys() {
                linguist_code.push_str(&format!(
                    "        {}.insert(Languages::{}, &{}_{});\n",
                    big_sect,
                    fix_case(lang),
                    big_sect,
                    lang.to_ascii_uppercase()
                ));
            }
        }
        linguist_code.push_str("    }\n}\n");
    }

    linguist_code.push_str("pub(crate) fn init_all_maps() {\n");

    for sect in ACCEPTED_SECTIONS {
        linguist_code.push_str(&format!("    init_{}_map();\n", sect));
    }

    linguist_code.push_str("}\n");

    for sect in ACCEPTED_SECTIONS {
        let big_sect = sect.to_ascii_uppercase();

        linguist_code.push_str(&format!(
            "\npub(crate) fn compile_{}_map() -> BTreeMap<Languages, Vec<Pattern>> {{\n",
            sect
        ));

        linguist_code.push_str("    let mut gmap = BTreeMap::new();\n");

        linguist_code.push_str(&format!(
            r#"
    unsafe {{
        for lang in {}.keys() {{
            gmap.insert(*lang, vec![]);
            let m = gmap.get_mut(lang).unwrap();

            for val in {}[lang] {{
                m.push(Pattern::new(val).unwrap());
            }}
        }}
    }}

    gmap
}}
"#,
            big_sect, big_sect
        ));
    }

    let gen_file = Path::new(OUTPUT_FILE);

    File::create(gen_file)
        .expect("failed to create output file for linguist data")
        .write_all(linguist_code.as_bytes())
        .expect("failed to write output file for linguist data");
}

fn fix_case(s: &str) -> String {
    s.split(&['_', ' '])
        .map(|x| {
            let mut chs = x.chars();
            if let Some(c) = chs.next() {
                format!("{}{}", c.to_ascii_uppercase(), chs.collect::<String>())
            } else {
                String::new()
            }
        })
        .collect()
}
